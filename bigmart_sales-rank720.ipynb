{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INSARAJ22\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.mstats import winsorize\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category= UserWarning)\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "file='train'\n",
    "data = pd.read_csv(rf'{file}.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8523 entries, 0 to 8522\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            8523 non-null   object \n",
      " 1   Item_Weight                7060 non-null   float64\n",
      " 2   Item_Fat_Content           8523 non-null   object \n",
      " 3   Item_Visibility            8523 non-null   float64\n",
      " 4   Item_Type                  8523 non-null   object \n",
      " 5   Item_MRP                   8523 non-null   float64\n",
      " 6   Outlet_Identifier          8523 non-null   object \n",
      " 7   Outlet_Establishment_Year  8523 non-null   int64  \n",
      " 8   Outlet_Size                6113 non-null   object \n",
      " 9   Outlet_Location_Type       8523 non-null   object \n",
      " 10  Outlet_Type                8523 non-null   object \n",
      " 11  Item_Outlet_Sales          8523 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 799.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the data-set info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier               0.000000\n",
       "Item_Weight                  17.165317\n",
       "Item_Fat_Content              0.000000\n",
       "Item_Visibility               0.000000\n",
       "Item_Type                     0.000000\n",
       "Item_MRP                      0.000000\n",
       "Outlet_Identifier             0.000000\n",
       "Outlet_Establishment_Year     0.000000\n",
       "Outlet_Size                  28.276428\n",
       "Outlet_Location_Type          0.000000\n",
       "Outlet_Type                   0.000000\n",
       "Item_Outlet_Sales             0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "(data.isnull().sum() / len(data)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **Only two cols has missing items Item_Weight and Outlet_Size**\n",
    "###### **Item_Weight has 17% missing values and Outlet_Size has 28% missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categoral Cols: ['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']\n",
      "Numerical Cols: ['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year', 'Item_Outlet_Sales', 'quantiyty']\n"
     ]
    }
   ],
   "source": [
    "# Identify the categorical cols in the data\n",
    "categorical_cols = ['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', \n",
    "                    'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']\n",
    "numerical_cols = ['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year', 'Item_Outlet_Sales', 'quantiyty']\n",
    "print(f\"Categoral Cols: {categorical_cols}\")\n",
    "print(f\"Numerical Cols: {numerical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data[\"Item_Fat_Content\"].value_counts() / len(data[\"Item_Fat_Content\"])) * 100\n",
    "\n",
    "# remove the inconsistencies\n",
    "data[\"Item_Fat_Content\"] = data[\"Item_Fat_Content\"].replace(\n",
    "    {\"LF\": \"Low Fat\",\n",
    "    \"low fat\": \"Low Fat\",\n",
    "    \"reg\": \"Regular\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low Fat' 'Regular']\n"
     ]
    }
   ],
   "source": [
    "print(data[\"Item_Fat_Content\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **ItemFatContent has two anomalies LF and reg they should be Low Fat and Regular**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the correlation among the features\n",
    "# plt.figure(figsize= (16, 10))\n",
    "# sns.heatmap(data[numerical_cols].corr(), annot= True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **Outlet Sales have high correlation with Item_MRP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INSARAJ22\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "C:\\Users\\INSARAJ22\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "C:\\Users\\INSARAJ22\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "C:\\Users\\INSARAJ22\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "# Treat the missing values\n",
    "# The distribution of the Item_Weight is uniform (so Mean ~ Median ~ Mode) and no outliers\n",
    "# Same items should have the same weight\n",
    "data[\"Item_Weight\"] = data.groupby(\"Item_Identifier\")[\"Item_Weight\"].transform(lambda x: x.fillna(x.median()))\n",
    "data[\"Outlet_Size\"] = data.groupby(\"Outlet_Type\")[\"Outlet_Size\"].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "# Still some values are missing so impute them using\n",
    "data[\"Item_Weight\"] = data.groupby([\"Item_Fat_Content\", \"Item_Type\"])[\"Item_Weight\"].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Encodes categorical variables in the dataset as per the encoding strategy.\n",
    "    Ensures a robust transformation for production-level implementation.\n",
    "    \"\"\"\n",
    "    df[\"Outlet_Age\"] = 2013 - df[\"Outlet_Establishment_Year\"]\n",
    "    df[\"Price_Per_Weight\"] = df[\"Item_MRP\"] / df[\"Item_Weight\"]\n",
    "    df.drop(\"Outlet_Age\", axis = 1, inplace = True)\n",
    "    #  Feature Extraction from Item_Identifier --------------------\n",
    "    df[\"Item_Category\"] = df[\"Item_Type\"].replace({\n",
    "    \"Dairy\": \"Perishable\",\n",
    "    \"Meat\": \"Perishable\",\n",
    "    \"Fruits and Vegetables\": \"Perishable\",\n",
    "    \"Baking Goods\": \"Processed\",\n",
    "    \"Breakfast\": \"Processed\",\n",
    "    \"Canned\": \"Processed\",\n",
    "    \"Frozen Foods\": \"Processed\",\n",
    "    \"Hard Drinks\": \"Drinks\",\n",
    "    \"Soft Drinks\": \"Drinks\",\n",
    "    \"Health and Hygiene\": \"Non-Food\",\n",
    "    \"Household\": \"Non-Food\",\n",
    "    \"Others\": \"Non-Food\",\n",
    "    \"Seafood\": \"Perishable\",\n",
    "    \"Snack Foods\": \"Processed\",\n",
    "    \"Starchy Foods\": \"Processed\"\n",
    "    })\n",
    "    df.drop([\"Item_Identifier\"], axis= 1, inplace = True) # drop the cols \n",
    "\n",
    "    # Label Encoding --------------------\n",
    "    label_encoders = {}\n",
    "\n",
    "    # Label encode Outlet_Identifier (as it represents unique stores)\n",
    "    label_encoders[\"Outlet_Identifier\"] = LabelEncoder()\n",
    "    df[\"Outlet_Identifier\"] = label_encoders[\"Outlet_Identifier\"].fit_transform(df[\"Outlet_Identifier\"])\n",
    "\n",
    "    # Label encode Outlet_Size (Small=0, Medium=1, Large=2)\n",
    "    size_mapping = {\"Small\": 0, \"Medium\": 1, \"High\": 2}\n",
    "    df[\"Outlet_Size\"] = df[\"Outlet_Size\"].map(size_mapping)\n",
    "\n",
    "    # Label encode Item_Fat_Content (Low Fat = 1, Regular = 0)\n",
    "    fat_mapping = {\"Low Fat\": 1, \"Regular\": 0}\n",
    "    df[\"Item_Fat_Content\"] = df[\"Item_Fat_Content\"].replace(fat_mapping)\n",
    "\n",
    "    # One-Hot Encoding --------------------\n",
    "    one_hot_cols = [\"Item_Category\", \"Outlet_Location_Type\", \"Outlet_Type\"]\n",
    "    df = pd.get_dummies(df, columns=one_hot_cols, drop_first=True)  # Drop first to avoid multicollinearity\n",
    "\n",
    "    # Also one-hot encode the extracted Item_Category_Code\n",
    "    df = pd.get_dummies(df, columns=[\"Item_Category_Code\"], drop_first=True)\n",
    "\n",
    "    # Final Check & Return --------------------\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "# df_encoded = encode_data(df)\n",
    "# print(df_encoded.head())\n",
    "\n",
    "\n",
    "# Fix the 0 Item_Visibilities\n",
    "def fix_item_visiblity(data,item_visibility_median,item_weight_medians,outlet_size_modes,outlet_size_modes_2,item_weight_medians_2):\n",
    "    \"\"\"Replace zero values in Item_Visibility using median visibility of that item\"\"\"\n",
    "    median_visibilty_per_item = data.groupby(\"Item_Identifier\")[\"Item_Visibility\"].median()\n",
    "    data.loc[data[\"Item_Visibility\"] == 0, \"Item_Visibility\"] = data[\"Item_Identifier\"].map(median_visibilty_per_item)\n",
    "    \n",
    "    # If NaN still exist replace with overall median\n",
    "    data[\"Item_Visibility\"].fillna(item_visibility_median, inplace= True)\n",
    "\n",
    "    # Step 2: Fill missing values in train data\n",
    "#     data[\"Item_Weight\"] = data[\"Item_Weight\"].fillna(data[\"Item_Identifier\"].map(item_weight_medians))\n",
    "#     data[\"Outlet_Size\"] = data[\"Outlet_Size\"].fillna(data[\"Outlet_Type\"].map(outlet_size_modes))\n",
    "#     data[\"Item_Weight\"] = data[\"Item_Weight\"].fillna(data[[\"Item_Fat_Content\", \"Item_Type\"]].apply(lambda x: item_weight_medians_2.get(tuple(x)), axis=1))\n",
    "#     data[\"Outlet_Size\"] = data[\"Outlet_Size\"].fillna(data[[\"Outlet_Type\", \"Outlet_Location_Type\"]].apply(lambda x: outlet_size_modes_2.get(tuple(x)), axis=1))\n",
    "\n",
    "\n",
    "    data[\"Item_Weight\"] = data.groupby(\"Item_Identifier\")[\"Item_Weight\"].transform(lambda x: x.fillna(x.median()))\n",
    "    data[\"Outlet_Size\"] = data.groupby(\"Outlet_Type\")[\"Outlet_Size\"].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    # Still some values are missing so impute them using\n",
    "    data[\"Outlet_Size\"] = data.groupby([\"Outlet_Type\", \"Outlet_Location_Type\"])[\"Outlet_Size\"].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    data[\"Item_Weight\"] = data.groupby([\"Item_Fat_Content\", \"Item_Type\"])[\"Item_Weight\"].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    data[\"Item_Fat_Content\"] = data[\"Item_Fat_Content\"].replace(\n",
    "    {\"LF\": \"Low Fat\",\n",
    "    \"low fat\": \"Low Fat\",\n",
    "    \"reg\": \"Regular\"}\n",
    "    )\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparams(X, y, n_trials=50):\n",
    "    \"\"\"\n",
    "    Optimizes hyperparameters for XGBoost and Random Forest using Optuna.\n",
    "    Returns the best trained model and its parameters.\n",
    "    \"\"\"\n",
    "    def objective(trial):\n",
    "        model_type = trial.suggest_categorical(\"model_type\", [\"xgboost\", \"random_forest\"])\n",
    "        \n",
    "        if model_type == \"xgboost\":\n",
    "            params = {\n",
    "                \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [1,2,3,4,5,7,10,20,50,75,100,200,500,700]),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 2,30),\n",
    "                \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.0001,0.001,0.005,0.01,0.05,0.1,0.3,0.5]),\n",
    "#                 \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "                \"gamma\":trial.suggest_categorical(\"gamma\", [0.01,0.05,0.1,0.3,0.5,1,5,10]),\n",
    "                \"min_child_weight\":trial.suggest_categorical(\"min_child_weight\", [0.01,0.05,0.1,0.3,0.5,1,5,10]),\n",
    "                \"colsample_bytree\": trial.suggest_categorical(\"colsample_bytree\", [0.2,0.5,0.7,1.0]),\n",
    "#                 \"reg_alpha\": trial.suggest_categorical(\"reg_alpha\", [0.01,0.05,0.1,0.3,0.5,1,5,10]),\n",
    "                \"reg_lambda\": trial.suggest_categorical(\"reg_lambda\", [0.01,0.05,0.1,0.3,0.5,1,5,10])\n",
    "            }\n",
    "            model = xgb.XGBRegressor(**params, objective=\"reg:squarederror\", random_state=101)\n",
    "        \n",
    "        else:  # Random Forest\n",
    "            params = {\n",
    "                \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [1,2,3,4,5,7,10,20,50,75,100,200,500,700]),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 2,30),\n",
    "                \"min_samples_split\": trial.suggest_categorical(\"min_samples_split\", [2,3,4,5,7,10,15,20,30]),\n",
    "                \"min_samples_leaf\": trial.suggest_categorical(\"min_samples_leaf\", [2,3,4,5,7,10,15,20,30]),\n",
    "                \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
    "            }\n",
    "            model = RandomForestRegressor(**params, random_state=101, n_jobs=-1)\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "        return np.mean(scores)  # Maximize negative RMSE (minimizing RMSE)\n",
    "\n",
    "    # Run Optuna optimization\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    # Get the best model type and parameters\n",
    "    best_params = study.best_params\n",
    "    best_model_type = best_params.pop(\"model_type\")\n",
    "\n",
    "    # Train the final best model\n",
    "    if best_model_type == \"xgboost\":\n",
    "        best_model = xgb.XGBRegressor(**best_params, objective=\"reg:squarederror\", random_state=42)\n",
    "    else:\n",
    "        best_model = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)\n",
    "\n",
    "    # Fit the best model on the full dataset\n",
    "    best_model.fit(X, y)\n",
    "\n",
    "    return best_model, best_params, study, best_model_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute median values from the train data\n",
    "if file=='train':\n",
    "    item_weight_medians = data.groupby(\"Item_Identifier\")[\"Item_Weight\"].median()\n",
    "    item_visibility_median=data['Item_Visibility'].median()\n",
    "    # 1st Imputation - Using Outlet_Type\n",
    "    outlet_size_modes = data.groupby(\"Outlet_Type\")[\"Outlet_Size\"].agg(lambda x: x.mode()[0] if not x.mode().empty else None)\n",
    "\n",
    "    # 2nd Imputation - Using Outlet_Type and Outlet_Location_Type\n",
    "    \n",
    "    outlet_size_modes_2 = data.groupby([\"Outlet_Type\", \"Outlet_Location_Type\"])[\"Outlet_Size\"].agg(lambda x: x.mode()[0] if not x.mode().empty else None)\n",
    "    # 3rd Imputation - Using Item_Fat_Content and Item_Type\n",
    "    item_weight_medians_2 = data.groupby([\"Item_Fat_Content\", \"Item_Type\"])[\"Item_Weight\"].median()\n",
    "\n",
    "processed_data = fix_item_visiblity(data.copy(),item_visibility_median,item_weight_medians,outlet_size_modes,outlet_size_modes_2,item_weight_medians_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = processed_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Outlet_Age\"] = 2025 - df[\"Outlet_Establishment_Year\"]\n",
    "df[\"Price_Per_Weight\"] = df[\"Item_MRP\"] / df[\"Item_Weight\"]\n",
    "df[\"Item_Category_Code\"] = df[\"Item_Identifier\"].apply(lambda x: x[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Item_Category\"] = df[\"Item_Type\"].replace({\n",
    "\"Dairy\": \"Perishable\",\n",
    "\"Meat\": \"Perishable\",\n",
    "\"Fruits and Vegetables\": \"Perishable\",\n",
    "\"Baking Goods\": \"Processed\",\n",
    "\"Breakfast\": \"Processed\",\n",
    "\"Canned\": \"Processed\",\n",
    "\"Frozen Foods\": \"Processed\",\n",
    "\"Hard Drinks\": \"Drinks\",\n",
    "\"Soft Drinks\": \"Drinks\",\n",
    "\"Health and Hygiene\": \"Non-Food\",\n",
    "\"Household\": \"Non-Food\",\n",
    "\"Others\": \"Non-Food\",\n",
    "\"Seafood\": \"Perishable\",\n",
    "\"Snack Foods\": \"Processed\",\n",
    "\"Starchy Foods\": \"Processed\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding --------------------\n",
    "label_encoders = {}\n",
    "\n",
    "# Label encode Outlet_Identifier (as it represents unique stores)\n",
    "# label_encoders[\"Outlet_Identifier\"] = LabelEncoder()\n",
    "# df[\"Outlet_Identifier\"] = label_encoders[\"Outlet_Identifier\"].fit_transform(df[\"Outlet_Identifier\"])\n",
    "\n",
    "# Label encode Outlet_Size (Small=0, Medium=1, Large=2)\n",
    "# size_mapping = {\"Small\": 0, \"Medium\": 1, \"High\": 2}\n",
    "# df[\"Outlet_Size\"] = df[\"Outlet_Size\"].map(size_mapping)\n",
    "\n",
    "# Label encode Item_Fat_Content (Low Fat = 1, Regular = 0)\n",
    "fat_mapping = {\"Tier 1\": 2, \"Tier 2\": 1, \"Tier 3\": 0}\n",
    "df[\"Outlet_Location_Type\"] = df[\"Outlet_Location_Type\"].replace(fat_mapping)\n",
    "\n",
    "fat_mapping = {\"Grocery Store\": 0, \"Supermarket Type3\": 1, \"Supermarket Type2\":1, \"Supermarket Type1\":1}\n",
    "df[\"Outlet_Type\"] = df[\"Outlet_Type\"].replace(fat_mapping)\n",
    "\n",
    "fat_mapping = {\"Low Fat\": 0, \"Regular\": 1}\n",
    "df[\"Item_Fat_Content\"] = df[\"Item_Fat_Content\"].replace(fat_mapping)\n",
    "one_hot_cols = [\"Outlet_Type\",\"Outlet_Identifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(rf'{file}_transformed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>Outlet_Age</th>\n",
       "      <th>Price_Per_Weight</th>\n",
       "      <th>Item_Category_Code</th>\n",
       "      <th>Item_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3735.1380</td>\n",
       "      <td>26</td>\n",
       "      <td>26.861204</td>\n",
       "      <td>FD</td>\n",
       "      <td>Perishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>443.4228</td>\n",
       "      <td>16</td>\n",
       "      <td>8.153581</td>\n",
       "      <td>DR</td>\n",
       "      <td>Drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2097.2700</td>\n",
       "      <td>26</td>\n",
       "      <td>8.092457</td>\n",
       "      <td>FD</td>\n",
       "      <td>Perishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022861</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>Small</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>732.3800</td>\n",
       "      <td>27</td>\n",
       "      <td>9.484115</td>\n",
       "      <td>FD</td>\n",
       "      <td>Perishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006590</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>994.7052</td>\n",
       "      <td>38</td>\n",
       "      <td>6.031512</td>\n",
       "      <td>NC</td>\n",
       "      <td>Non-Food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight  Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30                 0         0.016047   \n",
       "1           DRC01         5.92                 1         0.019278   \n",
       "2           FDN15        17.50                 0         0.016760   \n",
       "3           FDX07        19.20                 1         0.022861   \n",
       "4           NCD19         8.93                 0         0.006590   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size  Outlet_Location_Type  Outlet_Type  \\\n",
       "0                       1999      Medium                     2            1   \n",
       "1                       2009      Medium                     0            1   \n",
       "2                       1999      Medium                     2            1   \n",
       "3                       1998       Small                     0            0   \n",
       "4                       1987        High                     0            1   \n",
       "\n",
       "   Item_Outlet_Sales  Outlet_Age  Price_Per_Weight Item_Category_Code  \\\n",
       "0          3735.1380          26         26.861204                 FD   \n",
       "1           443.4228          16          8.153581                 DR   \n",
       "2          2097.2700          26          8.092457                 FD   \n",
       "3           732.3800          27          9.484115                 FD   \n",
       "4           994.7052          38          6.031512                 NC   \n",
       "\n",
       "  Item_Category  \n",
       "0    Perishable  \n",
       "1        Drinks  \n",
       "2    Perishable  \n",
       "3    Perishable  \n",
       "4      Non-Food  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
       "       'Item_Type', 'Item_MRP', 'Outlet_Identifier',\n",
       "       'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n",
       "       'Outlet_Type', 'Item_Outlet_Sales', 'Outlet_Age', 'Price_Per_Weight',\n",
       "       'Item_Category_Code', 'Item_Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop=[\"Item_Type\", \"Item_Identifier\", \"Item_Category_Code\", \"Item_Category\",\n",
    "             \"Outlet_Establishment_Year\",\"Outlet_Location_Type\",\"Outlet_Size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def train(one_hot_cols):\n",
    "    df=pd.read_csv('train_transformed.csv')\n",
    "    df.drop(columns_to_drop, axis= 1, inplace = True) # drop the cols \n",
    "\n",
    "    # One-Hot Encoding\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    one_hot_encoded = encoder.fit_transform(df[one_hot_cols])\n",
    "    one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(one_hot_cols))\n",
    "    df = pd.concat([df.drop(one_hot_cols, axis=1), one_hot_df], axis=1)\n",
    "    \n",
    "    #splitting\n",
    "    X=df.drop('Item_Outlet_Sales',axis=1)\n",
    "    y=df['Item_Outlet_Sales']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    #training\n",
    "    best_model, best_params, study, best_model_type=optimize_hyperparams(X_train,y_train)\n",
    "    y_pred=best_model.predict(X_test)\n",
    "    rms = mean_squared_error(y_pred, y_test, squared=False)\n",
    "    print(rms)\n",
    "    \n",
    "    fi=pd.DataFrame(df.drop('Item_Outlet_Sales',axis=1).columns,columns=['Columns'])\n",
    "    fi['Feature importance']=best_model.feature_importances_*100\n",
    "    \n",
    "    #train the best model on full data\n",
    "    if best_model_type == \"xgboost\":\n",
    "        model = xgb.XGBRegressor(**best_params, objective=\"reg:squarederror\", random_state=101, n_jobs=-1)\n",
    "    else:\n",
    "        model = RandomForestRegressor(**best_params, random_state=101, n_jobs=-1)\n",
    "    model.fit(X=df.drop('Item_Outlet_Sales',axis=1),y=df['Item_Outlet_Sales'])\n",
    "    \n",
    "    return model, best_params, study, rms, encoder, fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-01 03:57:16,513] A new study created in memory with name: no-name-2a646e4d-f8a1-4a0a-8c6a-df8bf0abad83\n",
      "[W 2025-02-01 03:57:16,518] Trial 0 failed with parameters: {'model_type': 'xgboost', 'n_estimators': 20, 'max_depth': 12, 'learning_rate': 0.0001, 'gamma': 0.5, 'min_child_weight': 5, 'colsample_bytree': 1.0, 'reg_lambda': 0.05} because of the following error: AttributeError(\"'super' object has no attribute '__sklearn_tags__'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\INSARAJ22\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\INSARAJ22\\AppData\\Local\\Temp\\ipykernel_19032\\3294885818.py\", line 34, in objective\n",
      "    scores = cross_val_score(model, X, y, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\INSARAJ22\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\INSARAJ22\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 684, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\INSARAJ22\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\INSARAJ22\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 347, in cross_validate\n",
      "    cv = check_cv(cv, y, classifier=is_classifier(estimator))\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\INSARAJ22\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\base.py\", line 1237, in is_classifier\n",
      "    return get_tags(estimator).estimator_type == \"classifier\"\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\INSARAJ22\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\utils\\_tags.py\", line 430, in get_tags\n",
      "    sklearn_tags_provider[klass] = klass.__sklearn_tags__(estimator)  # type: ignore[attr-defined]\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\INSARAJ22\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\base.py\", line 613, in __sklearn_tags__\n",
      "    tags = super().__sklearn_tags__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'super' object has no attribute '__sklearn_tags__'\n",
      "[W 2025-02-01 03:57:16,633] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#execute only for training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_model, best_params, study, rms, encoder, fi\u001b[38;5;241m=\u001b[39mtrain(one_hot_cols)\n\u001b[0;32m      3\u001b[0m fi\n",
      "Cell \u001b[1;32mIn[36], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(one_hot_cols)\u001b[0m\n\u001b[0;32m     16\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.33\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#training\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m best_model, best_params, study, best_model_type\u001b[38;5;241m=\u001b[39moptimize_hyperparams(X_train,y_train)\n\u001b[0;32m     20\u001b[0m y_pred\u001b[38;5;241m=\u001b[39mbest_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     21\u001b[0m rms \u001b[38;5;241m=\u001b[39m mean_squared_error(y_pred, y_test, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[24], line 39\u001b[0m, in \u001b[0;36moptimize_hyperparams\u001b[1;34m(X, y, n_trials)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Run Optuna optimization\u001b[39;00m\n\u001b[0;32m     38\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39mn_trials)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Get the best model type and parameters\u001b[39;00m\n\u001b[0;32m     42\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\optuna\\study\\study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     _optimize(\n\u001b[0;32m    443\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    444\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    445\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    446\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    447\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    448\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    449\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    450\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    451\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    452\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[24], line 34\u001b[0m, in \u001b[0;36moptimize_hyperparams.<locals>.objective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     31\u001b[0m     model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m101\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Perform cross-validation\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_val_score(model, X, y, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg_root_mean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(scores)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:684\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    682\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 684\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[0;32m    685\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    686\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    687\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    688\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    689\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[0;32m    690\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m    691\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    692\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    693\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    694\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[0;32m    695\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    696\u001b[0m )\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:347\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    345\u001b[0m X, y \u001b[38;5;241m=\u001b[39m indexable(X, y)\n\u001b[0;32m    346\u001b[0m params \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m params\n\u001b[1;32m--> 347\u001b[0m cv \u001b[38;5;241m=\u001b[39m check_cv(cv, y, classifier\u001b[38;5;241m=\u001b[39mis_classifier(estimator))\n\u001b[0;32m    349\u001b[0m scorers \u001b[38;5;241m=\u001b[39m check_scoring(\n\u001b[0;32m    350\u001b[0m     estimator, scoring\u001b[38;5;241m=\u001b[39mscoring, raise_exc\u001b[38;5;241m=\u001b[39m(error_score \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    351\u001b[0m )\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;66;03m# For estimators, a MetadataRouter is created in get_metadata_routing\u001b[39;00m\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;66;03m# methods. For these router methods, we create the router to use\u001b[39;00m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# `process_routing` on it.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\base.py:1237\u001b[0m, in \u001b[0;36mis_classifier\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m   1230\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing a class to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mprint\u001b[39m(inspect\u001b[38;5;241m.\u001b[39mstack()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1232\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in 1.8. Use an instance of the class instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1233\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1234\u001b[0m     )\n\u001b[0;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_estimator_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_tags(estimator)\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\utils\\_tags.py:430\u001b[0m, in \u001b[0;36mget_tags\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[1;32m--> 430\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m klass\u001b[38;5;241m.\u001b[39m__sklearn_tags__(estimator)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    431\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\base.py:613\u001b[0m, in \u001b[0;36mRegressorMixin.__sklearn_tags__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 613\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m__sklearn_tags__()\n\u001b[0;32m    614\u001b[0m     tags\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    615\u001b[0m     tags\u001b[38;5;241m.\u001b[39mregressor_tags \u001b[38;5;241m=\u001b[39m RegressorTags()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columns</th>\n",
       "      <th>Feature importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Item_Weight</td>\n",
       "      <td>3.585264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Item_Fat_Content</td>\n",
       "      <td>0.316948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Item_Visibility</td>\n",
       "      <td>2.465384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Item_MRP</td>\n",
       "      <td>36.974926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Outlet_Age</td>\n",
       "      <td>5.281721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Price_Per_Weight</td>\n",
       "      <td>18.193258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Outlet_Type_0</td>\n",
       "      <td>9.853572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Outlet_Type_1</td>\n",
       "      <td>10.935565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Outlet_Identifier_OUT010</td>\n",
       "      <td>2.769981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Outlet_Identifier_OUT013</td>\n",
       "      <td>0.124038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Outlet_Identifier_OUT017</td>\n",
       "      <td>0.107681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Outlet_Identifier_OUT018</td>\n",
       "      <td>0.413574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Outlet_Identifier_OUT019</td>\n",
       "      <td>2.226530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Outlet_Identifier_OUT027</td>\n",
       "      <td>6.171165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Outlet_Identifier_OUT035</td>\n",
       "      <td>0.120685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Outlet_Identifier_OUT045</td>\n",
       "      <td>0.183524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Outlet_Identifier_OUT046</td>\n",
       "      <td>0.145566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Outlet_Identifier_OUT049</td>\n",
       "      <td>0.130619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Columns  Feature importance\n",
       "0                Item_Weight            3.585264\n",
       "1           Item_Fat_Content            0.316948\n",
       "2            Item_Visibility            2.465384\n",
       "3                   Item_MRP           36.974926\n",
       "4                 Outlet_Age            5.281721\n",
       "5           Price_Per_Weight           18.193258\n",
       "6              Outlet_Type_0            9.853572\n",
       "7              Outlet_Type_1           10.935565\n",
       "8   Outlet_Identifier_OUT010            2.769981\n",
       "9   Outlet_Identifier_OUT013            0.124038\n",
       "10  Outlet_Identifier_OUT017            0.107681\n",
       "11  Outlet_Identifier_OUT018            0.413574\n",
       "12  Outlet_Identifier_OUT019            2.226530\n",
       "13  Outlet_Identifier_OUT027            6.171165\n",
       "14  Outlet_Identifier_OUT035            0.120685\n",
       "15  Outlet_Identifier_OUT045            0.183524\n",
       "16  Outlet_Identifier_OUT046            0.145566\n",
       "17  Outlet_Identifier_OUT049            0.130619"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#execute only for training\n",
    "best_model, best_params, study, rms, encoder, fi=train(one_hot_cols)\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INSARAJ22\\AppData\\Local\\Temp\\ipykernel_15104\\1239011212.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_submit['Item_Outlet_Sales']=pred\n"
     ]
    }
   ],
   "source": [
    "#generate test results\n",
    "df_test=pd.read_csv('test_transformed.csv')\n",
    "df_test.drop(columns_to_drop, axis= 1, inplace = True)\n",
    "\n",
    "# One-Hot Encoding --------------------\n",
    "one_hot_encoded = encoder.transform(df_test[one_hot_cols])\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(one_hot_cols))\n",
    "df_test = pd.concat([df_test.drop(one_hot_cols, axis=1), one_hot_df], axis=1)\n",
    "\n",
    "pred=best_model.predict(df_test)\n",
    "df_test=pd.read_csv('test_transformed.csv')\n",
    "df_submit=df_test[['Item_Identifier','Outlet_Identifier']]\n",
    "df_submit['Item_Outlet_Sales']=pred\n",
    "df_submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
