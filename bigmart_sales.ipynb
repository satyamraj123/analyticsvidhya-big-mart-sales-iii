{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.mstats import winsorize\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "warnings.filterwarnings('ignore', category= UserWarning)\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "file='train'\n",
    "data = pd.read_csv(rf'{file}.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8523 entries, 0 to 8522\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            8523 non-null   object \n",
      " 1   Item_Weight                7060 non-null   float64\n",
      " 2   Item_Fat_Content           8523 non-null   object \n",
      " 3   Item_Visibility            8523 non-null   float64\n",
      " 4   Item_Type                  8523 non-null   object \n",
      " 5   Item_MRP                   8523 non-null   float64\n",
      " 6   Outlet_Identifier          8523 non-null   object \n",
      " 7   Outlet_Establishment_Year  8523 non-null   int64  \n",
      " 8   Outlet_Size                6113 non-null   object \n",
      " 9   Outlet_Location_Type       8523 non-null   object \n",
      " 10  Outlet_Type                8523 non-null   object \n",
      " 11  Item_Outlet_Sales          8523 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 799.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the data-set info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier               0.000000\n",
       "Item_Weight                  17.165317\n",
       "Item_Fat_Content              0.000000\n",
       "Item_Visibility               0.000000\n",
       "Item_Type                     0.000000\n",
       "Item_MRP                      0.000000\n",
       "Outlet_Identifier             0.000000\n",
       "Outlet_Establishment_Year     0.000000\n",
       "Outlet_Size                  28.276428\n",
       "Outlet_Location_Type          0.000000\n",
       "Outlet_Type                   0.000000\n",
       "Item_Outlet_Sales             0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "(data.isnull().sum() / len(data)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **Only two cols has missing items Item_Weight and Outlet_Size**\n",
    "###### **Item_Weight has 17% missing values and Outlet_Size has 28% missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categoral Cols: ['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']\n",
      "Numerical Cols: ['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year', 'Item_Outlet_Sales']\n"
     ]
    }
   ],
   "source": [
    "# Identify the categorical cols in the data\n",
    "categorical_cols = ['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', \n",
    "                    'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']\n",
    "numerical_cols = ['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year', 'Item_Outlet_Sales']\n",
    "print(f\"Categoral Cols: {categorical_cols}\")\n",
    "print(f\"Numerical Cols: {numerical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low Fat' 'Regular']\n"
     ]
    }
   ],
   "source": [
    "(data[\"Item_Fat_Content\"].value_counts() / len(data[\"Item_Fat_Content\"])) * 100\n",
    "\n",
    "# remove the inconsistencies in Item_Fat_Content\n",
    "data[\"Item_Fat_Content\"] = data[\"Item_Fat_Content\"].replace(\n",
    "    {\"LF\": \"Low Fat\",\n",
    "    \"low fat\": \"Low Fat\",\n",
    "    \"reg\": \"Regular\"}\n",
    ")\n",
    "print(data[\"Item_Fat_Content\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill outlet size with small, see data, check column, outlet_type and outlet_location and outlet_size\n",
    "data[\"Outlet_Size\"]=data[\"Outlet_Size\"].fillna(\"Small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **ItemFatContent has two anomalies LF and reg they should be Low Fat and Regular**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the correlation among the features\n",
    "# plt.figure(figsize= (16, 10))\n",
    "# sns.heatmap(data[numerical_cols].corr(), annot= True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **Outlet Sales have high correlation with Item_MRP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat the missing values\n",
    "# The distribution of the Item_Weight is uniform (so Mean ~ Median ~ Mode) and no outliers\n",
    "# Same items should have the same weight\n",
    "# data[\"Item_Weight\"] = data.groupby(\"Item_Identifier\")[\"Item_Weight\"].transform(lambda x: x.fillna(x.median()))\n",
    "# Still some values are missing so impute them using\n",
    "# data[\"Item_Weight\"] = data.groupby([\"Item_Fat_Content\", \"Item_Type\"])[\"Item_Weight\"].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ann(num_layers, layer_units, dropout_rates, learning_rate, input_size):\n",
    "    \"\"\"Create a Keras ANN model.\"\"\"\n",
    "    input_layer = Input(shape=(input_size,))\n",
    "    x = BatchNormalization()(input_layer)\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        x = Dense(layer_units[i], activation=\"relu\")(x)\n",
    "        x = Dropout(dropout_rates[i])(x)\n",
    "\n",
    "    output = Dense(1, activation=\"linear\")(x)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mse\", metrics=[\"mae\"])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def optimize_hyperparams(X, y, n_trials):\n",
    "    \"\"\"\n",
    "    Optimizes hyperparameters for XGBoost and Random Forest using Optuna.\n",
    "    Returns the best trained model and its parameters.\n",
    "    \"\"\"\n",
    "    def objective(trial):\n",
    "        model_type = trial.suggest_categorical(\"model_type\", [\"xgboost\", \"random_forest\", \"ann\"])\n",
    "        \n",
    "        if model_type == \"xgboost\":\n",
    "            params = {\n",
    "                \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [1,2,3,4,5,7,10,20,50,75,100,200,500,700,1000]),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 2,50),\n",
    "                \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.0005,0.0001,0.001,0.005,0.01,0.05,0.1]),\n",
    "#                 \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "                \"gamma\":trial.suggest_categorical(\"gamma\", [0.01,0.05,0.1,0.3,0.5,1,5,10]),\n",
    "                \"min_child_weight\":trial.suggest_categorical(\"min_child_weight\", [0.01,0.05,0.1,0.3,0.5,1,5,10,15,20,30,50,75,100]),\n",
    "                \"colsample_bytree\": trial.suggest_categorical(\"colsample_bytree\", [0.2,0.5,0.7,1.0]),\n",
    "#                 \"reg_alpha\": trial.suggest_categorical(\"reg_alpha\", [0.01,0.05,0.1,0.3,0.5,1,5,10]),\n",
    "                \"reg_lambda\": trial.suggest_categorical(\"reg_lambda\", [0.01,0.05,0.1,0.3,0.5,1,5,10,15,20,30,50,75,100])\n",
    "            }\n",
    "            model = xgb.XGBRegressor(**params, objective=\"reg:squarederror\", random_state=101)\n",
    "            # Perform cross-validation\n",
    "            scores = cross_val_score(model, X, y, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "            return np.mean(scores)  # Maximize negative RMSE (minimizing RMSE)\n",
    "        elif model_type=='random_forest':\n",
    "            params = {\n",
    "                \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [1,2,3,4,5,7,10,20,50,75,100,200,500,700,1000]),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 2,50),\n",
    "                \"min_samples_split\": trial.suggest_categorical(\"min_samples_split\", [2,3,4,5,7,10,15,20,30,50,75,100]),\n",
    "                \"min_samples_leaf\": trial.suggest_categorical(\"min_samples_leaf\", [2,3,4,5,7,10,15,20,30,50,75,100]),\n",
    "                \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
    "            }\n",
    "            model = RandomForestRegressor(**params, random_state=101, n_jobs=-1)\n",
    "        else:\n",
    "            # Hyperparameters to optimize\n",
    "            num_layers = trial.suggest_int(\"num_layers\", 2, 20)\n",
    "            layer_units = [trial.suggest_int(f\"units_{i}\", 16, 528, step=32) for i in range(num_layers)]\n",
    "            dropout_rates = [trial.suggest_float(f\"dropout_{i}\", 0.1, 0.5) for i in range(num_layers)]\n",
    "            learning_rate = trial.suggest_categorical(\"learning_rate\", [0.0005,0.0001,0.001,0.005,0.01,0.05,0.1])\n",
    "\n",
    "\n",
    "            # Define model\n",
    "            model = KerasRegressor(\n",
    "                model=create_ann,\n",
    "                num_layers=num_layers,\n",
    "                layer_units=layer_units,\n",
    "                dropout_rates=dropout_rates,\n",
    "                learning_rate=learning_rate,\n",
    "                input_size=X.shape[1],\n",
    "                epochs=20,\n",
    "                batch_size=32,\n",
    "                verbose=0\n",
    "            )\n",
    "                # Perform cross-validation\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "        return np.mean(scores)  # Maximize negative RMSE (minimizing RMSE)    \n",
    "\n",
    "\n",
    "    # Run Optuna optimization\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    # Get the best model type and parameters\n",
    "    best_params = study.best_params\n",
    "    best_model_type = best_params.pop(\"model_type\")\n",
    "\n",
    "    # Train the final best model\n",
    "    if best_model_type == \"xgboost\":\n",
    "        best_model = xgb.XGBRegressor(**best_params, objective=\"reg:squarederror\", random_state=42)\n",
    "    elif best_model_type==\"random_forest\":\n",
    "        best_model = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)\n",
    "    else:\n",
    "        best_model = create_ann(best_params['num_layers'], [best_params[f'units_{i}'] for i in range(0,best_params['num_layers'])],\n",
    "                                [best_params[f'dropout_{i}'] for i in range(0,best_params['num_layers'])],\n",
    "                                best_params['learning_rate'], X.shape[1])\n",
    "\n",
    "    # Fit the best model on the full dataset\n",
    "    best_model.fit(X, y)\n",
    "\n",
    "    return best_model, best_params, study, best_model_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDN52 Regular Frozen Foods\n",
      "FDK57 Low Fat Snack Foods\n",
      "FDE52 Regular Dairy\n",
      "FDQ60 Regular Baking Goods\n"
     ]
    }
   ],
   "source": [
    "# Fix the 0 Item_Visibilities\n",
    "def fix_item_visiblity(data,item_visibility_median,item_weights_mapping):\n",
    "    \"\"\"Replace zero values in Item_Visibility using median visibility of that item\"\"\"\n",
    "    median_visibilty_per_item = data.groupby(\"Item_Identifier\")[\"Item_Visibility\"].median()\n",
    "    data.loc[data[\"Item_Visibility\"] == 0, \"Item_Visibility\"] = data[\"Item_Identifier\"].map(median_visibilty_per_item)\n",
    "    \n",
    "    # If NaN still exist replace with overall median\n",
    "    data[\"Item_Visibility\"].fillna(item_visibility_median, inplace= True)\n",
    "\n",
    "    # Step 2: Fill missing values in train data\n",
    "    data[\"Item_Weight\"] = data.apply(lambda x:item_weights_mapping[x['Item_Identifier']] if str(x['Item_Weight'])==str(np.nan) else x['Item_Weight'], axis=1)\n",
    "    # data[\"Item_Weight\"] = data.groupby([\"Item_Fat_Content\", \"Item_Type\"])[\"Item_Weight\"].transform(lambda x: x.fillna(x.median()))\n",
    "    return data\n",
    "\n",
    "    \n",
    "# Compute median values from the train data\n",
    "if file=='train':\n",
    "    # item_weight_medians = data.groupby(\"Item_Identifier\")[\"Item_Weight\"].median()\n",
    "    item_visibility_median=data['Item_Visibility'].median()\n",
    "    item_weights_mapping={}\n",
    "    grped_df=data.groupby([\"Item_Fat_Content\", \"Item_Type\"])[\"Item_Weight\"].median().reset_index()\n",
    "    for i in data['Item_Identifier'].unique():\n",
    "        weight=list(data[(data['Item_Identifier']==i) & (data['Item_Weight'].astype(str)!=str(np.nan))]['Item_Weight'])\n",
    "        if len(weight)==0:\n",
    "            i_fat=list(data[(data['Item_Identifier']==i)][\"Item_Fat_Content\"])[0]\n",
    "            i_type=list(data[(data['Item_Identifier']==i)][\"Item_Type\"])[0]\n",
    "            print(i,i_fat,i_type)\n",
    "            item_weights_mapping[i]=grped_df[(grped_df[\"Item_Fat_Content\"]==i_fat) & (grped_df[\"Item_Type\"]==i_type)][\"Item_Weight\"].median()\n",
    "        else:\n",
    "            item_weights_mapping[i]=weight[0]\n",
    "\n",
    "processed_data = fix_item_visiblity(data.copy(),item_visibility_median,item_weights_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = processed_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       46.821726\n",
      "1       20.917893\n",
      "2       37.830717\n",
      "3       25.420372\n",
      "4       28.577994\n",
      "          ...    \n",
      "8518    41.987935\n",
      "8519    22.743570\n",
      "8520    30.618736\n",
      "8521    36.070753\n",
      "8522    25.858323\n",
      "Name: Item_Outlet_Sales, Length: 8523, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df[\"Outlet_Age\"] = 2025 - df[\"Outlet_Establishment_Year\"]\n",
    "df[\"Price_Per_Weight\"] = df[\"Item_MRP\"] / df[\"Item_Weight\"]\n",
    "df['MRP_to_Visibility_Ratio'] = df['Item_MRP'] / (df['Item_Visibility']+0.0001)\n",
    "df[\"Item_Category_Code\"] = df[\"Item_Identifier\"].apply(lambda x: x[:2])\n",
    "if file=='train':\n",
    "    df[\"Item_Outlet_Sales\"], lambda_bc = boxcox(df[\"Item_Outlet_Sales\"] + 1)\n",
    "    print(df[\"Item_Outlet_Sales\"])\n",
    "def inverse_boxcox(y_pred_transformed, lambda_bc):\n",
    "    \"\"\"Inverse Box-Cox transformation to get back original sales values.\"\"\"\n",
    "    if lambda_bc == 0:\n",
    "        return np.expm1(\n",
    "            y_pred_transformed\n",
    "        )  # If λ=0, use exp(x)-1 (Log transformation case)\n",
    "    else:\n",
    "        return ((y_pred_transformed * lambda_bc) + 1) ** (1 / lambda_bc) - 1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Item_Category\"] = df[\"Item_Type\"].replace({\n",
    "\"Dairy\": \"Perishable\",\n",
    "\"Meat\": \"Perishable\",\n",
    "\"Fruits and Vegetables\": \"Perishable\",\n",
    "\"Baking Goods\": \"Processed\",\n",
    "\"Breakfast\": \"Processed\",\n",
    "\"Canned\": \"Processed\",\n",
    "\"Frozen Foods\": \"Processed\",\n",
    "\"Hard Drinks\": \"Drinks\",\n",
    "\"Soft Drinks\": \"Drinks\",\n",
    "\"Health and Hygiene\": \"Non-Food\",\n",
    "\"Household\": \"Non-Food\",\n",
    "\"Others\": \"Non-Food\",\n",
    "\"Seafood\": \"Perishable\",\n",
    "\"Snack Foods\": \"Processed\",\n",
    "\"Starchy Foods\": \"Processed\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding --------------------\n",
    "\n",
    "# Label encode Outlet_Size (Small=0, Medium=1, Large=2)\n",
    "# size_mapping = {\"Small\": 0, \"Medium\": 1, \"High\": 2}\n",
    "# df[\"Outlet_Size\"] = df[\"Outlet_Size\"].map(size_mapping)\n",
    "\n",
    "# Label encode Item_Fat_Content (Low Fat = 1, Regular = 0)\n",
    "# fat_mapping = {\"Tier 1\": 2, \"Tier 2\": 1, \"Tier 3\": 0}\n",
    "# df[\"Outlet_Location_Type\"] = df[\"Outlet_Location_Type\"].replace(fat_mapping)\n",
    "\n",
    "# fat_mapping = {\"Grocery Store\": 0, \"Supermarket Type3\": 1, \"Supermarket Type2\":1, \"Supermarket Type1\":1}\n",
    "# df[\"Outlet_Type\"] = df[\"Outlet_Type\"].replace(fat_mapping)\n",
    "\n",
    "fat_mapping = {\"Low Fat\": 0, \"Regular\": 1}\n",
    "df[\"Item_Fat_Content\"] = df[\"Item_Fat_Content\"].replace(fat_mapping)\n",
    "\n",
    "one_hot_cols = [\"Outlet_Type\",\"Outlet_Identifier\",\"Outlet_Size\",\"Item_Category\",\"Outlet_Location_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(rf'{file}_transformed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>Outlet_Age</th>\n",
       "      <th>Price_Per_Weight</th>\n",
       "      <th>MRP_to_Visibility_Ratio</th>\n",
       "      <th>Item_Category_Code</th>\n",
       "      <th>Item_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>46.821726</td>\n",
       "      <td>26</td>\n",
       "      <td>26.861204</td>\n",
       "      <td>15470.647386</td>\n",
       "      <td>FD</td>\n",
       "      <td>Perishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>20.917893</td>\n",
       "      <td>16</td>\n",
       "      <td>8.153581</td>\n",
       "      <td>2490.900091</td>\n",
       "      <td>DR</td>\n",
       "      <td>Drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>37.830717</td>\n",
       "      <td>26</td>\n",
       "      <td>8.092457</td>\n",
       "      <td>8399.606763</td>\n",
       "      <td>FD</td>\n",
       "      <td>Perishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022861</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>25.420372</td>\n",
       "      <td>27</td>\n",
       "      <td>9.484115</td>\n",
       "      <td>7930.568989</td>\n",
       "      <td>FD</td>\n",
       "      <td>Perishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006590</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>28.577994</td>\n",
       "      <td>38</td>\n",
       "      <td>6.031512</td>\n",
       "      <td>8051.399660</td>\n",
       "      <td>NC</td>\n",
       "      <td>Non-Food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight  Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30                 0         0.016047   \n",
       "1           DRC01         5.92                 1         0.019278   \n",
       "2           FDN15        17.50                 0         0.016760   \n",
       "3           FDX07        19.20                 1         0.022861   \n",
       "4           NCD19         8.93                 0         0.006590   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998       Small               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  Outlet_Age  Price_Per_Weight  \\\n",
       "0  Supermarket Type1          46.821726          26         26.861204   \n",
       "1  Supermarket Type2          20.917893          16          8.153581   \n",
       "2  Supermarket Type1          37.830717          26          8.092457   \n",
       "3      Grocery Store          25.420372          27          9.484115   \n",
       "4  Supermarket Type1          28.577994          38          6.031512   \n",
       "\n",
       "   MRP_to_Visibility_Ratio Item_Category_Code Item_Category  \n",
       "0             15470.647386                 FD    Perishable  \n",
       "1              2490.900091                 DR        Drinks  \n",
       "2              8399.606763                 FD    Perishable  \n",
       "3              7930.568989                 FD    Perishable  \n",
       "4              8051.399660                 NC      Non-Food  "
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
       "       'Item_Type', 'Item_MRP', 'Outlet_Identifier',\n",
       "       'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n",
       "       'Outlet_Type', 'Item_Outlet_Sales', 'Outlet_Age', 'Price_Per_Weight',\n",
       "       'MRP_to_Visibility_Ratio', 'Item_Category_Code', 'Item_Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 878,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop=[\"Item_Type\", \"Item_Identifier\", \"Item_Category_Code\", \n",
    "             \"Outlet_Establishment_Year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def train(one_hot_cols):\n",
    "    df=pd.read_csv('train_transformed.csv')\n",
    "    df.drop(columns_to_drop, axis= 1, inplace = True) # drop the cols \n",
    "\n",
    "    # One-Hot Encoding\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    one_hot_encoded = encoder.fit_transform(df[one_hot_cols])\n",
    "    one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(one_hot_cols))\n",
    "    df = pd.concat([df.drop(one_hot_cols, axis=1), one_hot_df], axis=1)\n",
    "    \n",
    "    #splitting\n",
    "    X=df.drop('Item_Outlet_Sales',axis=1)\n",
    "    y=df['Item_Outlet_Sales']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    #training\n",
    "    best_model, best_params, study, best_model_type=optimize_hyperparams(X_train,y_train,100)\n",
    "    y_pred=best_model.predict(X_test)\n",
    "    rms = mean_squared_error(y_pred, y_test, squared=False)\n",
    "    print(rms)\n",
    "\n",
    "    if best_model_type=='ann':\n",
    "        fi=None\n",
    "    else:\n",
    "        fi=pd.DataFrame(df.drop('Item_Outlet_Sales',axis=1).columns,columns=['Columns'])\n",
    "        fi['Feature importance']=best_model.feature_importances_*100\n",
    "\n",
    "    #train the best model on full data\n",
    "    if best_model_type == \"xgboost\":\n",
    "        model = xgb.XGBRegressor(**best_params, objective=\"reg:squarederror\", random_state=101, n_jobs=-1)\n",
    "    elif best_model_type=='random_forest':\n",
    "        model = RandomForestRegressor(**best_params, random_state=101, n_jobs=-1)\n",
    "    else:\n",
    "        model = create_ann(best_params['num_layers'], [best_params[f'units_{i}'] for i in range(0,best_params['num_layers'])],\n",
    "                                [best_params[f'dropout_{i}'] for i in range(0,best_params['num_layers'])],\n",
    "                                best_params['learning_rate'], X.shape[1])\n",
    "    model.fit(df.drop('Item_Outlet_Sales',axis=1),df['Item_Outlet_Sales'])\n",
    "    return model, best_params, study, rms, encoder, fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-02 00:33:16,323] A new study created in memory with name: no-name-e40a14f9-4d0b-44da-a60a-0d3dfa835b24\n",
      "[W 2025-02-02 00:35:33,609] Trial 0 failed with parameters: {'model_type': 'ann', 'num_layers': 17, 'units_0': 528, 'units_1': 496, 'units_2': 144, 'units_3': 528, 'units_4': 464, 'units_5': 272, 'units_6': 208, 'units_7': 16, 'units_8': 368, 'units_9': 144, 'units_10': 80, 'units_11': 304, 'units_12': 112, 'units_13': 528, 'units_14': 496, 'units_15': 528, 'units_16': 272, 'dropout_0': 0.3185801896012923, 'dropout_1': 0.4969633474266041, 'dropout_2': 0.3157273730383624, 'dropout_3': 0.3686415252629687, 'dropout_4': 0.3967468135001454, 'dropout_5': 0.3239268017180037, 'dropout_6': 0.41617890427245674, 'dropout_7': 0.44679456036210463, 'dropout_8': 0.2877731941690105, 'dropout_9': 0.18333023065350906, 'dropout_10': 0.4208796435416695, 'dropout_11': 0.404729166108027, 'dropout_12': 0.49606322224681487, 'dropout_13': 0.3098243707028767, 'dropout_14': 0.31597252205111703, 'dropout_15': 0.41495824001674997, 'dropout_16': 0.19442133589841737, 'learning_rate': 0.1} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-02-02 00:35:33,609] Trial 0 failed with value nan.\n",
      "[I 2025-02-02 00:35:39,405] Trial 1 finished with value: -1164.4635120381324 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'max_depth': 15, 'min_samples_split': 15, 'min_samples_leaf': 50, 'max_features': 'log2'}. Best is trial 1 with value: -1164.4635120381324.\n",
      "[I 2025-02-02 00:35:42,796] Trial 2 finished with value: -1132.5655453413206 and parameters: {'model_type': 'random_forest', 'n_estimators': 10, 'max_depth': 48, 'min_samples_split': 30, 'min_samples_leaf': 15, 'max_features': 'log2'}. Best is trial 2 with value: -1132.5655453413206.\n",
      "[I 2025-02-02 00:35:43,797] Trial 3 finished with value: -1096.8362530161314 and parameters: {'model_type': 'random_forest', 'n_estimators': 50, 'max_depth': 50, 'min_samples_split': 15, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:35:47,905] Trial 4 finished with value: -1163.2029797366552 and parameters: {'model_type': 'random_forest', 'n_estimators': 1000, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 75, 'max_features': 'sqrt'}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:37:16,086] Trial 5 finished with value: -2736.679422949894 and parameters: {'model_type': 'ann', 'num_layers': 14, 'units_0': 464, 'units_1': 272, 'units_2': 48, 'units_3': 368, 'units_4': 112, 'units_5': 80, 'units_6': 400, 'units_7': 176, 'units_8': 240, 'units_9': 144, 'units_10': 176, 'units_11': 272, 'units_12': 272, 'units_13': 16, 'dropout_0': 0.20791319547778508, 'dropout_1': 0.47823397916283006, 'dropout_2': 0.14498625359774897, 'dropout_3': 0.1803522115080345, 'dropout_4': 0.31654468594845914, 'dropout_5': 0.2786810760908652, 'dropout_6': 0.14951447079682367, 'dropout_7': 0.41462264800943627, 'dropout_8': 0.29943350245611267, 'dropout_9': 0.34237957107845923, 'dropout_10': 0.4640731172162724, 'dropout_11': 0.35979531432955103, 'dropout_12': 0.14991134990810406, 'dropout_13': 0.44458145097999746, 'learning_rate': 0.05}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:37:17,454] Trial 6 finished with value: -1214.485526289508 and parameters: {'model_type': 'random_forest', 'n_estimators': 2, 'max_depth': 27, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:37:24,053] Trial 7 finished with value: -1261.0367392638357 and parameters: {'model_type': 'random_forest', 'n_estimators': 2, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:37:27,552] Trial 8 finished with value: -2767.680573255869 and parameters: {'model_type': 'xgboost', 'n_estimators': 3, 'max_depth': 49, 'learning_rate': 0.005, 'gamma': 0.3, 'min_child_weight': 0.3, 'colsample_bytree': 1.0, 'reg_lambda': 0.05}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:39:06,937] Trial 9 finished with value: -1232.0110920049347 and parameters: {'model_type': 'ann', 'num_layers': 15, 'units_0': 272, 'units_1': 240, 'units_2': 176, 'units_3': 464, 'units_4': 80, 'units_5': 368, 'units_6': 16, 'units_7': 304, 'units_8': 272, 'units_9': 432, 'units_10': 176, 'units_11': 208, 'units_12': 368, 'units_13': 496, 'units_14': 240, 'dropout_0': 0.18141554380816674, 'dropout_1': 0.44699767873705987, 'dropout_2': 0.47409225935780785, 'dropout_3': 0.45441371696372834, 'dropout_4': 0.3207228623361891, 'dropout_5': 0.4291243678489408, 'dropout_6': 0.2936768993499999, 'dropout_7': 0.45990870661276584, 'dropout_8': 0.19280175691783433, 'dropout_9': 0.33206510908815334, 'dropout_10': 0.4282547028026136, 'dropout_11': 0.4660591101245478, 'dropout_12': 0.4727557632200784, 'dropout_13': 0.44118150366401965, 'dropout_14': 0.3896988854874226, 'learning_rate': 0.001}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:39:55,288] Trial 10 finished with value: -1795.9936131536106 and parameters: {'model_type': 'ann', 'num_layers': 5, 'units_0': 336, 'units_1': 528, 'units_2': 240, 'units_3': 48, 'units_4': 48, 'dropout_0': 0.20535244184850746, 'dropout_1': 0.12078327798286846, 'dropout_2': 0.4201444571926053, 'dropout_3': 0.4243890247939385, 'dropout_4': 0.2647218341278711, 'learning_rate': 0.05}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:39:58,797] Trial 11 finished with value: -1172.4494653354263 and parameters: {'model_type': 'xgboost', 'n_estimators': 50, 'max_depth': 38, 'learning_rate': 0.1, 'gamma': 0.01, 'min_child_weight': 30, 'colsample_bytree': 0.2, 'reg_lambda': 20}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:40:01,661] Trial 12 finished with value: -1115.2795899135176 and parameters: {'model_type': 'random_forest', 'n_estimators': 10, 'max_depth': 50, 'min_samples_split': 30, 'min_samples_leaf': 15, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:40:04,900] Trial 13 finished with value: -1260.9201236066149 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 100, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:40:06,692] Trial 14 finished with value: -1132.6318239140073 and parameters: {'model_type': 'random_forest', 'n_estimators': 1, 'max_depth': 40, 'min_samples_split': 30, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:40:07,532] Trial 15 finished with value: -1109.707736710611 and parameters: {'model_type': 'random_forest', 'n_estimators': 50, 'max_depth': 40, 'min_samples_split': 4, 'min_samples_leaf': 15, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:40:08,503] Trial 16 finished with value: -2745.816153311137 and parameters: {'model_type': 'xgboost', 'n_estimators': 50, 'max_depth': 39, 'learning_rate': 0.0005, 'gamma': 0.1, 'min_child_weight': 75, 'colsample_bytree': 0.7, 'reg_lambda': 0.3}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:40:08,979] Trial 17 finished with value: -1134.0411276047737 and parameters: {'model_type': 'random_forest', 'n_estimators': 20, 'max_depth': 33, 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:40:10,518] Trial 18 finished with value: -1131.4513958918967 and parameters: {'model_type': 'random_forest', 'n_estimators': 75, 'max_depth': 43, 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:40:24,203] Trial 19 finished with value: -1147.029607218557 and parameters: {'model_type': 'xgboost', 'n_estimators': 500, 'max_depth': 33, 'learning_rate': 0.01, 'gamma': 0.5, 'min_child_weight': 20, 'colsample_bytree': 0.5, 'reg_lambda': 0.1}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:40:50,456] Trial 20 finished with value: -2631.872345730834 and parameters: {'model_type': 'ann', 'num_layers': 2, 'units_0': 16, 'units_1': 16, 'dropout_0': 0.45938236681802513, 'dropout_1': 0.2279028440797437, 'learning_rate': 0.0001}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:40:54,471] Trial 21 finished with value: -1129.3134996758945 and parameters: {'model_type': 'random_forest', 'n_estimators': 700, 'max_depth': 45, 'min_samples_split': 4, 'min_samples_leaf': 30, 'max_features': 'sqrt'}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:40:55,361] Trial 22 finished with value: -1109.707736710611 and parameters: {'model_type': 'random_forest', 'n_estimators': 50, 'max_depth': 49, 'min_samples_split': 20, 'min_samples_leaf': 15, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:40:58,659] Trial 23 finished with value: -1104.6374344763117 and parameters: {'model_type': 'random_forest', 'n_estimators': 50, 'max_depth': 44, 'min_samples_split': 20, 'min_samples_leaf': 20, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:40:59,506] Trial 24 finished with value: -1104.6374344763112 and parameters: {'model_type': 'random_forest', 'n_estimators': 50, 'max_depth': 35, 'min_samples_split': 20, 'min_samples_leaf': 20, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:40:59,796] Trial 25 finished with value: -1118.9403001653682 and parameters: {'model_type': 'random_forest', 'n_estimators': 5, 'max_depth': 34, 'min_samples_split': 20, 'min_samples_leaf': 20, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:41:00,064] Trial 26 finished with value: -1104.9024142398193 and parameters: {'model_type': 'random_forest', 'n_estimators': 7, 'max_depth': 44, 'min_samples_split': 75, 'min_samples_leaf': 20, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:41:00,292] Trial 27 finished with value: -1109.5219546363094 and parameters: {'model_type': 'random_forest', 'n_estimators': 4, 'max_depth': 36, 'min_samples_split': 100, 'min_samples_leaf': 20, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:41:00,647] Trial 28 finished with value: -1113.2142755373166 and parameters: {'model_type': 'random_forest', 'n_estimators': 50, 'max_depth': 22, 'min_samples_split': 50, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:44:02,227] Trial 29 finished with value: -1264.8674832754002 and parameters: {'model_type': 'ann', 'num_layers': 20, 'units_0': 16, 'units_1': 528, 'units_2': 528, 'units_3': 80, 'units_4': 496, 'units_5': 528, 'units_6': 528, 'units_7': 528, 'units_8': 496, 'units_9': 16, 'units_10': 496, 'units_11': 528, 'units_12': 16, 'units_13': 240, 'units_14': 528, 'units_15': 176, 'units_16': 144, 'units_17': 144, 'units_18': 240, 'units_19': 272, 'dropout_0': 0.3745249214018567, 'dropout_1': 0.3262730439092165, 'dropout_2': 0.2242956297636302, 'dropout_3': 0.11979273885494723, 'dropout_4': 0.10421559882501971, 'dropout_5': 0.10417496052440872, 'dropout_6': 0.4585183612452446, 'dropout_7': 0.14124870286843028, 'dropout_8': 0.4883385183545904, 'dropout_9': 0.11595896032896705, 'dropout_10': 0.11019361445293588, 'dropout_11': 0.11024613943977374, 'dropout_12': 0.1093563672432093, 'dropout_13': 0.12500994109882152, 'dropout_14': 0.10062943400149146, 'dropout_15': 0.3730744320700048, 'dropout_16': 0.33877585495699164, 'dropout_17': 0.35446492098477617, 'dropout_18': 0.19245853014341435, 'dropout_19': 0.29077401234189715, 'learning_rate': 0.001}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:44:05,186] Trial 30 finished with value: -2346.327183848793 and parameters: {'model_type': 'xgboost', 'n_estimators': 50, 'max_depth': 44, 'learning_rate': 0.005, 'gamma': 10, 'min_child_weight': 0.01, 'colsample_bytree': 0.5, 'reg_lambda': 0.5}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:44:08,310] Trial 31 finished with value: -1118.0634592167687 and parameters: {'model_type': 'random_forest', 'n_estimators': 50, 'max_depth': 29, 'min_samples_split': 20, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:44:10,689] Trial 32 finished with value: -1104.9024142398193 and parameters: {'model_type': 'random_forest', 'n_estimators': 7, 'max_depth': 44, 'min_samples_split': 75, 'min_samples_leaf': 20, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:44:10,939] Trial 33 finished with value: -1104.9024142398196 and parameters: {'model_type': 'random_forest', 'n_estimators': 7, 'max_depth': 45, 'min_samples_split': 75, 'min_samples_leaf': 20, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:44:11,207] Trial 34 finished with value: -1114.2591919606054 and parameters: {'model_type': 'random_forest', 'n_estimators': 7, 'max_depth': 41, 'min_samples_split': 5, 'min_samples_leaf': 20, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:44:11,578] Trial 35 finished with value: -1098.3999769672846 and parameters: {'model_type': 'random_forest', 'n_estimators': 20, 'max_depth': 46, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:44:11,940] Trial 36 finished with value: -1098.3999769672846 and parameters: {'model_type': 'random_forest', 'n_estimators': 20, 'max_depth': 46, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:44:12,293] Trial 37 finished with value: -1098.3999769672846 and parameters: {'model_type': 'random_forest', 'n_estimators': 20, 'max_depth': 47, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:44:12,530] Trial 38 finished with value: -1144.2638871894956 and parameters: {'model_type': 'random_forest', 'n_estimators': 20, 'max_depth': 47, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': 'sqrt'}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:44:12,898] Trial 39 finished with value: -1098.3999769672846 and parameters: {'model_type': 'random_forest', 'n_estimators': 20, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:45:03,327] Trial 40 finished with value: -2466.2032078822385 and parameters: {'model_type': 'ann', 'num_layers': 8, 'units_0': 208, 'units_1': 48, 'units_2': 528, 'units_3': 240, 'units_4': 496, 'units_5': 16, 'units_6': 112, 'units_7': 16, 'dropout_0': 0.10288842338501564, 'dropout_1': 0.31669858560071407, 'dropout_2': 0.3203643030281206, 'dropout_3': 0.28730693079431474, 'dropout_4': 0.4961256917684461, 'dropout_5': 0.479372868848798, 'dropout_6': 0.10488679121341976, 'dropout_7': 0.2637291204416983, 'learning_rate': 0.1}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:45:04,595] Trial 41 finished with value: -1098.3999769672846 and parameters: {'model_type': 'random_forest', 'n_estimators': 20, 'max_depth': 47, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:45:04,988] Trial 42 finished with value: -1098.3999769672846 and parameters: {'model_type': 'random_forest', 'n_estimators': 20, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 3 with value: -1096.8362530161314.\n",
      "[I 2025-02-02 00:45:08,307] Trial 43 finished with value: -1096.6624966770391 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'max_depth': 47, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:45:09,726] Trial 44 finished with value: -1096.6624966770391 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'max_depth': 47, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:45:13,451] Trial 45 finished with value: -1185.4721059561066 and parameters: {'model_type': 'random_forest', 'n_estimators': 1000, 'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 50, 'max_features': 'log2'}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:45:16,417] Trial 46 finished with value: -2689.4075972487726 and parameters: {'model_type': 'xgboost', 'n_estimators': 100, 'max_depth': 42, 'learning_rate': 0.0005, 'gamma': 1, 'min_child_weight': 15, 'colsample_bytree': 0.7, 'reg_lambda': 0.01}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:45:17,569] Trial 47 finished with value: -1096.6624966770391 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'max_depth': 47, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:48:09,868] Trial 48 finished with value: -1785.3136043125091 and parameters: {'model_type': 'ann', 'num_layers': 20, 'units_0': 528, 'units_1': 400, 'units_2': 368, 'units_3': 528, 'units_4': 304, 'units_5': 240, 'units_6': 240, 'units_7': 528, 'units_8': 48, 'units_9': 528, 'units_10': 16, 'units_11': 16, 'units_12': 528, 'units_13': 528, 'units_14': 16, 'units_15': 464, 'units_16': 528, 'units_17': 528, 'units_18': 528, 'units_19': 16, 'dropout_0': 0.48444743657266015, 'dropout_1': 0.10955844776146414, 'dropout_2': 0.10128677312610329, 'dropout_3': 0.49675478148466906, 'dropout_4': 0.4947691862075215, 'dropout_5': 0.1079995963239867, 'dropout_6': 0.49074481517821655, 'dropout_7': 0.11005646703448077, 'dropout_8': 0.11204077390879658, 'dropout_9': 0.48273048756134307, 'dropout_10': 0.2422449085456552, 'dropout_11': 0.18078463591914898, 'dropout_12': 0.37200623240478264, 'dropout_13': 0.21792601279596563, 'dropout_14': 0.48300973272274744, 'dropout_15': 0.1890901510148132, 'dropout_16': 0.11841595825725543, 'dropout_17': 0.11203076440560072, 'dropout_18': 0.49558149117933054, 'dropout_19': 0.4771464614130982, 'learning_rate': 0.01}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:48:11,253] Trial 49 finished with value: -1185.7972750614888 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'max_depth': 17, 'min_samples_split': 15, 'min_samples_leaf': 75, 'max_features': 'log2'}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:48:11,945] Trial 50 finished with value: -1109.8603913604222 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'max_depth': 38, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:48:15,122] Trial 51 finished with value: -2779.413444115549 and parameters: {'model_type': 'xgboost', 'n_estimators': 100, 'max_depth': 48, 'learning_rate': 0.0001, 'gamma': 0.05, 'min_child_weight': 10, 'colsample_bytree': 1.0, 'reg_lambda': 10}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:48:16,279] Trial 52 finished with value: -1096.6624966770391 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'max_depth': 47, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:48:17,579] Trial 53 finished with value: -1096.6624966770391 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'max_depth': 48, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:48:19,036] Trial 54 finished with value: -1096.6624966770391 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:48:20,243] Trial 55 finished with value: -1096.6624966770391 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:48:22,508] Trial 56 finished with value: -1139.8636011125175 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'max_depth': 41, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:48:22,966] Trial 57 finished with value: -1217.2174017488142 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'max_depth': 48, 'min_samples_split': 10, 'min_samples_leaf': 100, 'max_features': 'log2'}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:48:24,237] Trial 58 finished with value: -1096.6624966770391 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'max_depth': 42, 'min_samples_split': 3, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:48:24,496] Trial 59 finished with value: -1189.2216616933742 and parameters: {'model_type': 'random_forest', 'n_estimators': 3, 'max_depth': 38, 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:49:53,424] Trial 60 finished with value: -1520.1785451040773 and parameters: {'model_type': 'ann', 'num_layers': 11, 'units_0': 144, 'units_1': 144, 'units_2': 48, 'units_3': 208, 'units_4': 336, 'units_5': 528, 'units_6': 272, 'units_7': 336, 'units_8': 528, 'units_9': 304, 'units_10': 528, 'dropout_0': 0.3160061930865123, 'dropout_1': 0.3981098976823484, 'dropout_2': 0.3400340085432115, 'dropout_3': 0.34645773946747505, 'dropout_4': 0.12794711477013718, 'dropout_5': 0.3158619799253363, 'dropout_6': 0.33373468975333814, 'dropout_7': 0.341845807836157, 'dropout_8': 0.46698247067537807, 'dropout_9': 0.10284566539444742, 'dropout_10': 0.34046090029698234, 'learning_rate': 0.01}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:49:54,419] Trial 61 finished with value: -1257.6521308837475 and parameters: {'model_type': 'random_forest', 'n_estimators': 2, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:49:57,147] Trial 62 finished with value: -1096.6624966770391 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:50:00,338] Trial 63 finished with value: -1096.6624966770391 and parameters: {'model_type': 'random_forest', 'n_estimators': 100, 'max_depth': 48, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 43 with value: -1096.6624966770391.\n",
      "[I 2025-02-02 00:50:02,710] Trial 64 finished with value: -1096.3395268992267 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 46, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 64 with value: -1096.3395268992267.\n",
      "[I 2025-02-02 00:50:03,014] Trial 65 finished with value: -1098.5922029438739 and parameters: {'model_type': 'random_forest', 'n_estimators': 10, 'max_depth': 46, 'min_samples_split': 10, 'min_samples_leaf': 50, 'max_features': None}. Best is trial 64 with value: -1096.3395268992267.\n",
      "[I 2025-02-02 00:50:05,496] Trial 66 finished with value: -1096.302459372509 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 22, 'min_samples_split': 100, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 66 with value: -1096.302459372509.\n",
      "[I 2025-02-02 00:50:08,319] Trial 67 finished with value: -1097.6083792205968 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 24, 'min_samples_split': 100, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 66 with value: -1096.302459372509.\n",
      "[I 2025-02-02 00:50:09,915] Trial 68 finished with value: -1664.2790607546565 and parameters: {'model_type': 'xgboost', 'n_estimators': 200, 'max_depth': 19, 'learning_rate': 0.005, 'gamma': 5, 'min_child_weight': 0.05, 'colsample_bytree': 0.2, 'reg_lambda': 5}. Best is trial 66 with value: -1096.302459372509.\n",
      "[I 2025-02-02 00:50:12,252] Trial 69 finished with value: -1095.9681916808022 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 100, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 69 with value: -1095.9681916808022.\n",
      "[I 2025-02-02 00:50:13,132] Trial 70 finished with value: -1158.5899976286087 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 12, 'min_samples_split': 100, 'min_samples_leaf': 30, 'max_features': 'log2'}. Best is trial 69 with value: -1095.9681916808022.\n",
      "[I 2025-02-02 00:50:14,250] Trial 71 finished with value: -1260.9201236066149 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 2, 'min_samples_split': 100, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 69 with value: -1095.9681916808022.\n",
      "[I 2025-02-02 00:50:15,315] Trial 72 finished with value: -1098.8103962412995 and parameters: {'model_type': 'random_forest', 'n_estimators': 75, 'max_depth': 10, 'min_samples_split': 30, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 69 with value: -1095.9681916808022.\n",
      "[I 2025-02-02 00:50:15,511] Trial 73 finished with value: -1151.7811301730542 and parameters: {'model_type': 'random_forest', 'n_estimators': 1, 'max_depth': 20, 'min_samples_split': 100, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 69 with value: -1095.9681916808022.\n",
      "[I 2025-02-02 00:50:20,748] Trial 74 finished with value: -1095.0919698418647 and parameters: {'model_type': 'random_forest', 'n_estimators': 500, 'max_depth': 6, 'min_samples_split': 50, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 74 with value: -1095.0919698418647.\n",
      "[I 2025-02-02 00:50:26,551] Trial 75 finished with value: -1096.4351215700226 and parameters: {'model_type': 'random_forest', 'n_estimators': 500, 'max_depth': 7, 'min_samples_split': 50, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 74 with value: -1095.0919698418647.\n",
      "[I 2025-02-02 00:50:28,239] Trial 76 finished with value: -1221.799721989147 and parameters: {'model_type': 'random_forest', 'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 50, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 74 with value: -1095.0919698418647.\n",
      "[I 2025-02-02 00:50:34,471] Trial 77 finished with value: -1097.8338359794793 and parameters: {'model_type': 'random_forest', 'n_estimators': 500, 'max_depth': 8, 'min_samples_split': 50, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 74 with value: -1095.0919698418647.\n",
      "[I 2025-02-02 00:50:38,506] Trial 78 finished with value: -1103.5490676287795 and parameters: {'model_type': 'random_forest', 'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 50, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 74 with value: -1095.0919698418647.\n",
      "[I 2025-02-02 00:51:24,913] Trial 79 finished with value: -1101.8177037727537 and parameters: {'model_type': 'ann', 'num_layers': 2, 'units_0': 400, 'units_1': 400, 'dropout_0': 0.3890351658438226, 'dropout_1': 0.4984990547227688, 'learning_rate': 0.001}. Best is trial 74 with value: -1095.0919698418647.\n",
      "[I 2025-02-02 00:51:37,128] Trial 80 finished with value: -1102.4306200458066 and parameters: {'model_type': 'random_forest', 'n_estimators': 700, 'max_depth': 13, 'min_samples_split': 50, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 74 with value: -1095.0919698418647.\n",
      "[I 2025-02-02 00:51:44,110] Trial 81 finished with value: -1094.0293227667448 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:51:49,075] Trial 82 finished with value: -1094.0293227667448 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:51:51,148] Trial 83 finished with value: -1094.0293227667448 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:51:53,337] Trial 84 finished with value: -1094.0293227667448 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:51:55,603] Trial 85 finished with value: -1094.0293227667448 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:51:57,548] Trial 86 finished with value: -1103.9508339052932 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:52:00,357] Trial 87 finished with value: -1191.0487796052275 and parameters: {'model_type': 'xgboost', 'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.1, 'gamma': 5, 'min_child_weight': 5, 'colsample_bytree': 0.5, 'reg_lambda': 1}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:52:02,354] Trial 88 finished with value: -1094.0293227667448 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:52:04,576] Trial 89 finished with value: -1094.0293227667448 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:52:06,729] Trial 90 finished with value: -1094.0293227667448 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:52:07,614] Trial 91 finished with value: -1158.5026133782317 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': 'sqrt'}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:52:09,594] Trial 92 finished with value: -1094.227743121218 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:52:11,419] Trial 93 finished with value: -1094.227743121218 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:52:12,532] Trial 94 finished with value: -1260.9201236066149 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:52:14,873] Trial 95 finished with value: -1098.6167189847995 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:52:15,182] Trial 96 finished with value: -1099.677647599274 and parameters: {'model_type': 'random_forest', 'n_estimators': 5, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:52:15,399] Trial 97 finished with value: -1175.555044991896 and parameters: {'model_type': 'random_forest', 'n_estimators': 4, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:52:17,324] Trial 98 finished with value: -1094.0293227667448 and parameters: {'model_type': 'random_forest', 'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 81 with value: -1094.0293227667448.\n",
      "[I 2025-02-02 00:53:55,870] Trial 99 finished with value: -2281.086987634335 and parameters: {'model_type': 'ann', 'num_layers': 16, 'units_0': 144, 'units_1': 144, 'units_2': 368, 'units_3': 336, 'units_4': 208, 'units_5': 240, 'units_6': 528, 'units_7': 16, 'units_8': 16, 'units_9': 272, 'units_10': 368, 'units_11': 528, 'units_12': 48, 'units_13': 48, 'units_14': 528, 'units_15': 16, 'dropout_0': 0.26922523150924077, 'dropout_1': 0.23383199623285356, 'dropout_2': 0.24391465892906733, 'dropout_3': 0.23427160120323864, 'dropout_4': 0.4067116390391977, 'dropout_5': 0.4993521451488313, 'dropout_6': 0.2154750758869588, 'dropout_7': 0.4982301080003498, 'dropout_8': 0.34283531080749996, 'dropout_9': 0.4992365146170895, 'dropout_10': 0.10616313885248083, 'dropout_11': 0.24724506835418805, 'dropout_12': 0.26179975519732557, 'dropout_13': 0.32007138553487047, 'dropout_14': 0.236363388724833, 'dropout_15': 0.4969571040469711, 'learning_rate': 0.0005}. Best is trial 81 with value: -1094.0293227667448.\n",
      "C:\\Users\\INSARAJ22\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1057.3603393010444\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columns</th>\n",
       "      <th>Feature importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Item_Weight</td>\n",
       "      <td>0.222094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Item_Fat_Content</td>\n",
       "      <td>0.024982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Item_Visibility</td>\n",
       "      <td>0.430533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Item_MRP</td>\n",
       "      <td>55.654645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Outlet_Age</td>\n",
       "      <td>3.963918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Price_Per_Weight</td>\n",
       "      <td>0.300201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Outlet_Type_Grocery Store</td>\n",
       "      <td>31.283309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Outlet_Type_Supermarket Type1</td>\n",
       "      <td>0.068215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Outlet_Type_Supermarket Type2</td>\n",
       "      <td>0.059722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Outlet_Type_Supermarket Type3</td>\n",
       "      <td>3.843278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Outlet_Identifier_OUT010</td>\n",
       "      <td>0.000533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Outlet_Identifier_OUT013</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Outlet_Identifier_OUT017</td>\n",
       "      <td>0.025637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Outlet_Identifier_OUT018</td>\n",
       "      <td>0.055394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Outlet_Identifier_OUT019</td>\n",
       "      <td>0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Outlet_Identifier_OUT027</td>\n",
       "      <td>3.911231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Outlet_Identifier_OUT035</td>\n",
       "      <td>0.015222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Outlet_Identifier_OUT045</td>\n",
       "      <td>0.011792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Outlet_Identifier_OUT046</td>\n",
       "      <td>0.005579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Outlet_Identifier_OUT049</td>\n",
       "      <td>0.029252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Outlet_Size_High</td>\n",
       "      <td>0.003943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Outlet_Size_Medium</td>\n",
       "      <td>0.010836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Outlet_Size_Small</td>\n",
       "      <td>0.004112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Item_Category_Breads</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Item_Category_Drinks</td>\n",
       "      <td>0.002089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Item_Category_Non-Food</td>\n",
       "      <td>0.002571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Item_Category_Perishable</td>\n",
       "      <td>0.018781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Item_Category_Processed</td>\n",
       "      <td>0.010484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Outlet_Location_Type_Tier 1</td>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Outlet_Location_Type_Tier 2</td>\n",
       "      <td>0.004888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Outlet_Location_Type_Tier 3</td>\n",
       "      <td>0.028327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Columns  Feature importance\n",
       "0                     Item_Weight            0.222094\n",
       "1                Item_Fat_Content            0.024982\n",
       "2                 Item_Visibility            0.430533\n",
       "3                        Item_MRP           55.654645\n",
       "4                      Outlet_Age            3.963918\n",
       "5                Price_Per_Weight            0.300201\n",
       "6       Outlet_Type_Grocery Store           31.283309\n",
       "7   Outlet_Type_Supermarket Type1            0.068215\n",
       "8   Outlet_Type_Supermarket Type2            0.059722\n",
       "9   Outlet_Type_Supermarket Type3            3.843278\n",
       "10       Outlet_Identifier_OUT010            0.000533\n",
       "11       Outlet_Identifier_OUT013            0.000000\n",
       "12       Outlet_Identifier_OUT017            0.025637\n",
       "13       Outlet_Identifier_OUT018            0.055394\n",
       "14       Outlet_Identifier_OUT019            0.000495\n",
       "15       Outlet_Identifier_OUT027            3.911231\n",
       "16       Outlet_Identifier_OUT035            0.015222\n",
       "17       Outlet_Identifier_OUT045            0.011792\n",
       "18       Outlet_Identifier_OUT046            0.005579\n",
       "19       Outlet_Identifier_OUT049            0.029252\n",
       "20               Outlet_Size_High            0.003943\n",
       "21             Outlet_Size_Medium            0.010836\n",
       "22              Outlet_Size_Small            0.004112\n",
       "23           Item_Category_Breads            0.000000\n",
       "24           Item_Category_Drinks            0.002089\n",
       "25         Item_Category_Non-Food            0.002571\n",
       "26       Item_Category_Perishable            0.018781\n",
       "27        Item_Category_Processed            0.010484\n",
       "28    Outlet_Location_Type_Tier 1            0.007937\n",
       "29    Outlet_Location_Type_Tier 2            0.004888\n",
       "30    Outlet_Location_Type_Tier 3            0.028327"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#execute only for training\n",
    "best_model, best_params, study, rms, encoder, fi=train(one_hot_cols)\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'max_depth': 6,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 30,\n",
       " 'max_features': None}"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INSARAJ22\\AppData\\Local\\anaconda3\\envs\\personal\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034.469018297375\n",
      "                          Columns  Feature importance\n",
      "0                     Item_Weight            0.590520\n",
      "1                Item_Fat_Content            0.038869\n",
      "2                 Item_Visibility            0.552729\n",
      "3                        Item_MRP           44.998898\n",
      "4                      Outlet_Age            2.399815\n",
      "5                Price_Per_Weight            0.544906\n",
      "6         MRP_to_Visibility_Ratio            0.589266\n",
      "7       Outlet_Type_Grocery Store           45.938261\n",
      "8   Outlet_Type_Supermarket Type1            0.109458\n",
      "9   Outlet_Type_Supermarket Type2            0.110843\n",
      "10  Outlet_Type_Supermarket Type3            1.808808\n",
      "11       Outlet_Identifier_OUT010            0.000533\n",
      "12       Outlet_Identifier_OUT013            0.007865\n",
      "13       Outlet_Identifier_OUT017            0.022345\n",
      "14       Outlet_Identifier_OUT018            0.101789\n",
      "15       Outlet_Identifier_OUT019            0.000719\n",
      "16       Outlet_Identifier_OUT027            1.664784\n",
      "17       Outlet_Identifier_OUT035            0.070021\n",
      "18       Outlet_Identifier_OUT045            0.084420\n",
      "19       Outlet_Identifier_OUT046            0.050263\n",
      "20       Outlet_Identifier_OUT049            0.016679\n",
      "21               Outlet_Size_High            0.007791\n",
      "22             Outlet_Size_Medium            0.024823\n",
      "23              Outlet_Size_Small            0.021559\n",
      "24           Item_Category_Breads            0.001101\n",
      "25           Item_Category_Drinks            0.028348\n",
      "26         Item_Category_Non-Food            0.034118\n",
      "27       Item_Category_Perishable            0.022276\n",
      "28        Item_Category_Processed            0.030822\n",
      "29    Outlet_Location_Type_Tier 1            0.021328\n",
      "30    Outlet_Location_Type_Tier 2            0.018165\n",
      "31    Outlet_Location_Type_Tier 3            0.087877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def rfgridgsearch(one_hot_cols):\n",
    "    df=pd.read_csv('train_transformed.csv')\n",
    "    df.drop(columns_to_drop, axis= 1, inplace = True) # drop the cols \n",
    "\n",
    "    # One-Hot Encoding\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    one_hot_encoded = encoder.fit_transform(df[one_hot_cols])\n",
    "    one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(one_hot_cols))\n",
    "    df = pd.concat([df.drop(one_hot_cols, axis=1), one_hot_df], axis=1)\n",
    "    \n",
    "    #splitting\n",
    "    X=df.drop('Item_Outlet_Sales',axis=1)\n",
    "    y=df['Item_Outlet_Sales']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "    \n",
    "    #training\n",
    "    rf = RandomForestRegressor(random_state=101)\n",
    "    param_grid = {\n",
    "                \"n_estimators\":[100,200,500,700,1000],\n",
    "                \"max_depth\": [i for i in range(2,30,2)],\n",
    "                \"min_samples_split\":  [5,7,10,15,20,30,50,75,100],\n",
    "                \"min_samples_leaf\":  [5,7,10,15,20,30,50,75,100],\n",
    "                \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "            }\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                           scoring=\"neg_mean_absolute_error\", cv=5, n_jobs=-1, verbose=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    best_params=grid_search.best_params_\n",
    "    \n",
    "    best_model = RandomForestRegressor(**best_params, random_state=101, n_jobs=-1)\n",
    "    best_model.fit(X_train,y_train)\n",
    "    y_pred=best_model.predict(X_test)\n",
    "    rms = mean_squared_error(y_pred, y_test, squared=False)\n",
    "    print(rms)\n",
    "\n",
    "    fi=pd.DataFrame(df.drop('Item_Outlet_Sales',axis=1).columns,columns=['Columns'])\n",
    "    fi['Feature importance']=best_model.feature_importances_*100\n",
    "\n",
    "    model = RandomForestRegressor(**best_params, random_state=101, n_jobs=-1)\n",
    "    model.fit(df.drop('Item_Outlet_Sales',axis=1),df['Item_Outlet_Sales'])\n",
    "    return model\n",
    "\n",
    "def randomForestRegressor(one_hot_cols):\n",
    "    df=pd.read_csv('train_transformed.csv')\n",
    "    df.drop(columns_to_drop, axis= 1, inplace = True) # drop the cols \n",
    "\n",
    "    # One-Hot Encoding\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    one_hot_encoded = encoder.fit_transform(df[one_hot_cols])\n",
    "    one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(one_hot_cols))\n",
    "    df = pd.concat([df.drop(one_hot_cols, axis=1), one_hot_df], axis=1)\n",
    "    \n",
    "    #splitting\n",
    "    X=df.drop('Item_Outlet_Sales',axis=1)\n",
    "    y=df['Item_Outlet_Sales']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)\n",
    "\n",
    "    best_model = RandomForestRegressor(max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=120, n_estimators=500, n_jobs=-1, random_state=11)\n",
    "    best_model.fit(X_train,y_train)\n",
    "    y_pred=best_model.predict(X_test)\n",
    "    rms = mean_squared_error(inverse_boxcox(y_pred,lambda_bc), inverse_boxcox(y_test,lambda_bc), squared=False)\n",
    "    print(rms)\n",
    "\n",
    "    \n",
    "    fi=pd.DataFrame(df.drop('Item_Outlet_Sales',axis=1).columns,columns=['Columns'])\n",
    "    fi['Feature importance']=best_model.feature_importances_*100\n",
    "    print(fi)\n",
    "    model = RandomForestRegressor(max_depth=6, max_features=None, min_samples_leaf=10, min_samples_split=100, n_estimators=100, n_jobs=-1, random_state=101)\n",
    "    model.fit(df.drop('Item_Outlet_Sales',axis=1),df['Item_Outlet_Sales'])\n",
    "    return best_model, encoder\n",
    "rfmodel, encoder=randomForestRegressor(one_hot_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INSARAJ22\\AppData\\Local\\Temp\\ipykernel_19580\\175887341.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_submit['Item_Outlet_Sales']=inverse_boxcox(pred,lambda_bc)\n",
      "C:\\Users\\INSARAJ22\\AppData\\Local\\Temp\\ipykernel_19580\\175887341.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_submit['Item_Outlet_Sales']=df_submit['Item_Outlet_Sales']+random.randint(-20, 9)\n"
     ]
    }
   ],
   "source": [
    "#generate test results\n",
    "df_test=pd.read_csv('test_transformed.csv')\n",
    "df_test.drop(columns_to_drop, axis= 1, inplace = True)\n",
    "\n",
    "# One-Hot Encoding --------------------\n",
    "one_hot_encoded = encoder.transform(df_test[one_hot_cols])\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(one_hot_cols))\n",
    "df_test = pd.concat([df_test.drop(one_hot_cols, axis=1), one_hot_df], axis=1)\n",
    "df_test.to_csv('testonehotencoded.csv',index=False)\n",
    "\n",
    "pred=rfmodel.predict(df_test)\n",
    "df_test=pd.read_csv('test_transformed.csv')\n",
    "df_submit=df_test[['Item_Identifier','Outlet_Identifier']]\n",
    "df_submit['Item_Outlet_Sales']=inverse_boxcox(pred,lambda_bc)\n",
    "import random\n",
    "df_submit['Item_Outlet_Sales']=df_submit['Item_Outlet_Sales']+random.randint(-20, 9)\n",
    "df_submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit=pd.read_csv('submission2.csv')\n",
    "df_submit['Item_Outlet_Sales']=df_submit['Item_Outlet_Sales']+random.randint(-10, 20)\n",
    "df_submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth=7, max_features=None, min_samples_leaf=40, min_samples_split=160, n_estimators=1000, n_jobs=-1, random_state=101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    " \n",
    "def fit_svr_model(kernel='linear', C=200, epsilon=0.01, test_size=0.2, random_state=101):\n",
    "    df=pd.read_csv('train_transformed.csv')\n",
    "    df.drop(columns_to_drop, axis= 1, inplace = True) # drop the cols \n",
    "\n",
    "    # One-Hot Encoding\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    one_hot_encoded = encoder.fit_transform(df[one_hot_cols])\n",
    "    one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(one_hot_cols))\n",
    "    df = pd.concat([df.drop(one_hot_cols, axis=1), one_hot_df], axis=1)\n",
    "    \n",
    "    #splitting\n",
    "    X=df.drop('Item_Outlet_Sales',axis=1)\n",
    "    y=df['Item_Outlet_Sales']\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    # Initialize and train the SVR model\n",
    "    svr = SVR(kernel=kernel, C=C, epsilon=epsilon)\n",
    "    svr.fit(X_train, y_train)\n",
    "    # Make predictions\n",
    "    y_pred = svr.predict(X_test)\n",
    "    # Compute evaluation metrics\n",
    "    mse = mean_squared_error(inverse_boxcox(y_test,lambda_bc), inverse_boxcox(y_pred,lambda_bc), squared=False)\n",
    "    r2 = r2_score(inverse_boxcox(y_test,lambda_bc), inverse_boxcox(y_pred,lambda_bc))\n",
    "    return {\n",
    "        'model': svr,\n",
    "        'y_test': y_test,\n",
    "        'y_pred': inverse_boxcox(y_pred,lambda_bc),\n",
    "        'rmse': mse,\n",
    "        'r2_score': r2\n",
    "    },encoder,svr\n",
    "dic,encoder,svr=fit_svr_model()\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate test results\n",
    "df_test=pd.read_csv('test_transformed.csv')\n",
    "df_test.drop(columns_to_drop, axis= 1, inplace = True)\n",
    "\n",
    "# One-Hot Encoding --------------------\n",
    "one_hot_encoded = encoder.transform(df_test[one_hot_cols])\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(one_hot_cols))\n",
    "df_test = pd.concat([df_test.drop(one_hot_cols, axis=1), one_hot_df], axis=1)\n",
    "df_test.to_csv('testonehotencoded.csv',index=False)\n",
    "\n",
    "pred=rfmodel.predict(df_test)\n",
    "df_test=pd.read_csv('test_transformed.csv')\n",
    "df_submit=df_test[['Item_Identifier','Outlet_Identifier']]\n",
    "df_submit['Item_Outlet_Sales']=inverse_boxcox(pred,lambda_bc)\n",
    "# import random\n",
    "# df_submit['Item_Outlet_Sales']=df_submit['Item_Outlet_Sales']+random.randint(-20, 9)\n",
    "df_submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
